{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Lab 8: K-Nearest Neighbors**\n---\n\n### **Description**\nIn this lab, you will implement KNN (K-Nearest Neighbors) models. KNNs are a popular machine learning algorithm used for classification and regression tasks. Through this lab, you'll gain hands-on experience in building and training KNN models and using them to make accurate predictions. You'll get to see firsthand how KNN models work and how they can be used to solve real-world problems.\n\n<br>\n\n### **Structure**\n**Part 1**: [Breast Cancer Dataset](#p1)\n\n**Part 2**: [Spotify Dataset](#p2)\n\n**Part 3**: [Australia Dataset](#p3)\n\n**Part 4**: [[OPTIONAL] Homework Practice](#p4)\n>\n> **Part 4.1**: [Zoo Animal Classification Dataset](#p4.1)\n>\n> **Part 4.2**: [Classifying Stars](#p4.2)\n>\n> **Part 4.3**: [RGB Color Classification](#p4.3)\n\n\n<br>\n\n### **Learning Objectives**\nBy the end of this lab, we will:\n* Recognize how to implement KNN models with sklearn.\n* Recognize how to evaluate KNN models with sklearn.\n\n<br>\n\n### **Resources**\n* [K-Nearest Neighbors with sklearn](https://docs.google.com/document/d/1rKyjjnRe5dq3StxXS03n6iXfJvTN7dJNJjWVGdCu6cM/edit?usp=sharing)\n\n* [pandas Commands](https://docs.google.com/document/d/1pLCyzig38Mop0Iib021X47S25WBEqZCWf7LRdpC8hGw/edit?usp=drive_link)\n\n* [Data Visualizations with matplotlib](https://docs.google.com/document/d/1tCKyB_E2A-S_rwTIN6JHE9lCQiK4DLTQTt25Lc-uQcs/edit?usp=drive_link)\n\n<br>\n\n**Before starting, run the code below to import all necessary functions and libraries.**","metadata":{"id":"nERhJ0C6rpDV"}},{"cell_type":"code","source":"!pip install numpy\n!pip install pandas\n!pip install matplot\n!pip install scikit-learn\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn import datasets, model_selection, metrics","metadata":{"id":"J697Qi0eizBL","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Collecting numpy\n  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\nDownloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\nInstalling collected packages: numpy\nSuccessfully installed numpy-2.2.6\nCollecting pandas\n  Downloading pandas-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\nRequirement already satisfied: numpy>=1.22.4 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from pandas) (2.2.6)\nRequirement already satisfied: python-dateutil>=2.8.2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from pandas) (2025.1)\nCollecting tzdata>=2022.7 (from pandas)\n  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nDownloading pandas-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\nDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\nInstalling collected packages: tzdata, pandas\nSuccessfully installed pandas-2.3.1 tzdata-2025.2\nCollecting matplot\n  Downloading matplot-0.1.9-py2.py3-none-any.whl.metadata (241 bytes)\nCollecting pyloco>=0.0.134 (from matplot)\n  Downloading pyloco-0.0.139-py2.py3-none-any.whl.metadata (1.1 kB)\nCollecting matplotlib>=3.1.1 (from matplot)\n  Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting contourpy>=1.0.1 (from matplotlib>=3.1.1->matplot)\n  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\nCollecting cycler>=0.10 (from matplotlib>=3.1.1->matplot)\n  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\nCollecting fonttools>=4.22.0 (from matplotlib>=3.1.1->matplot)\n  Downloading fonttools-4.59.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (107 kB)\nCollecting kiwisolver>=1.3.1 (from matplotlib>=3.1.1->matplot)\n  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\nRequirement already satisfied: numpy>=1.23 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from matplotlib>=3.1.1->matplot) (2.2.6)\nRequirement already satisfied: packaging>=20.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from matplotlib>=3.1.1->matplot) (24.2)\nCollecting pillow>=8 (from matplotlib>=3.1.1->matplot)\n  Downloading pillow-11.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\nCollecting pyparsing>=2.3.1 (from matplotlib>=3.1.1->matplot)\n  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\nRequirement already satisfied: python-dateutil>=2.7 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from matplotlib>=3.1.1->matplot) (2.9.0.post0)\nCollecting ushlex (from pyloco>=0.0.134->matplot)\n  Downloading ushlex-0.99.1.tar.gz (4.7 kB)\ndoneeparing metadata (setup.py) ... \u001b[?25l\n\u001b[?25hRequirement already satisfied: websocket-client in /srv/conda/envs/notebook/lib/python3.10/site-packages (from pyloco>=0.0.134->matplot) (1.8.0)\nCollecting twine (from pyloco>=0.0.134->matplot)\n  Downloading twine-6.1.0-py3-none-any.whl.metadata (3.7 kB)\nCollecting typing (from pyloco>=0.0.134->matplot)\n  Downloading typing-3.7.4.3.tar.gz (78 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting SimpleWebSocketServer (from pyloco>=0.0.134->matplot)\n  Downloading SimpleWebSocketServer-0.1.2.tar.gz (10 kB)\ndoneing metadata (setup.py) ... \u001b[?25l\n\u001b[?25hRequirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.1.1->matplot) (1.17.0)\nCollecting readme-renderer>=35.0 (from twine->pyloco>=0.0.134->matplot)\n  Downloading readme_renderer-44.0-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: requests>=2.20 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from twine->pyloco>=0.0.134->matplot) (2.32.3)\nCollecting requests-toolbelt!=0.9.0,>=0.8.0 (from twine->pyloco>=0.0.134->matplot)\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: urllib3>=1.26.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from twine->pyloco>=0.0.134->matplot) (2.3.0)\nCollecting keyring>=15.1 (from twine->pyloco>=0.0.134->matplot)\n  Downloading keyring-25.6.0-py3-none-any.whl.metadata (20 kB)\nCollecting rfc3986>=1.4.0 (from twine->pyloco>=0.0.134->matplot)\n  Downloading rfc3986-2.0.0-py2.py3-none-any.whl.metadata (6.6 kB)\nCollecting rich>=12.0.0 (from twine->pyloco>=0.0.134->matplot)\n  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\nCollecting id (from twine->pyloco>=0.0.134->matplot)\n  Downloading id-1.5.0-py3-none-any.whl.metadata (5.2 kB)\nCollecting SecretStorage>=3.2 (from keyring>=15.1->twine->pyloco>=0.0.134->matplot)\n  Downloading SecretStorage-3.3.3-py3-none-any.whl.metadata (4.0 kB)\nCollecting jeepney>=0.4.2 (from keyring>=15.1->twine->pyloco>=0.0.134->matplot)\n  Downloading jeepney-0.9.0-py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: importlib_metadata>=4.11.4 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from keyring>=15.1->twine->pyloco>=0.0.134->matplot) (8.6.1)\nCollecting jaraco.classes (from keyring>=15.1->twine->pyloco>=0.0.134->matplot)\n  Downloading jaraco.classes-3.4.0-py3-none-any.whl.metadata (2.6 kB)\nCollecting jaraco.functools (from keyring>=15.1->twine->pyloco>=0.0.134->matplot)\n  Downloading jaraco_functools-4.2.1-py3-none-any.whl.metadata (2.9 kB)\nCollecting jaraco.context (from keyring>=15.1->twine->pyloco>=0.0.134->matplot)\n  Downloading jaraco.context-6.0.1-py3-none-any.whl.metadata (4.1 kB)\nCollecting nh3>=0.2.14 (from readme-renderer>=35.0->twine->pyloco>=0.0.134->matplot)\n  Downloading nh3-0.2.22-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\nCollecting docutils>=0.21.2 (from readme-renderer>=35.0->twine->pyloco>=0.0.134->matplot)\n  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: Pygments>=2.5.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from readme-renderer>=35.0->twine->pyloco>=0.0.134->matplot) (2.19.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests>=2.20->twine->pyloco>=0.0.134->matplot) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests>=2.20->twine->pyloco>=0.0.134->matplot) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests>=2.20->twine->pyloco>=0.0.134->matplot) (2024.12.14)\nCollecting markdown-it-py>=2.2.0 (from rich>=12.0.0->twine->pyloco>=0.0.134->matplot)\n  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from rich>=12.0.0->twine->pyloco>=0.0.134->matplot) (4.12.2)\nRequirement already satisfied: zipp>=3.20 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from importlib_metadata>=4.11.4->keyring>=15.1->twine->pyloco>=0.0.134->matplot) (3.21.0)\nCollecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=12.0.0->twine->pyloco>=0.0.134->matplot)\n  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: cryptography>=2.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from SecretStorage>=3.2->keyring>=15.1->twine->pyloco>=0.0.134->matplot) (44.0.0)\nCollecting more-itertools (from jaraco.classes->keyring>=15.1->twine->pyloco>=0.0.134->matplot)\n  Downloading more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\nCollecting backports.tarfile (from jaraco.context->keyring>=15.1->twine->pyloco>=0.0.134->matplot)\n  Downloading backports.tarfile-1.2.0-py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: cffi>=1.12 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine->pyloco>=0.0.134->matplot) (1.17.1)\nRequirement already satisfied: pycparser in /srv/conda/envs/notebook/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine->pyloco>=0.0.134->matplot) (2.22)\nDownloading matplot-0.1.9-py2.py3-none-any.whl (5.0 kB)\nDownloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\nDownloading pyloco-0.0.139-py2.py3-none-any.whl (60 kB)\nDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\nDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\nDownloading fonttools-4.59.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\nDownloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\nDownloading pillow-11.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\nDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\nDownloading twine-6.1.0-py3-none-any.whl (40 kB)\nDownloading keyring-25.6.0-py3-none-any.whl (39 kB)\nDownloading readme_renderer-44.0-py3-none-any.whl (13 kB)\nDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\nDownloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\nDownloading rich-14.0.0-py3-none-any.whl (243 kB)\nDownloading id-1.5.0-py3-none-any.whl (13 kB)\nDownloading docutils-0.21.2-py3-none-any.whl (587 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\nDownloading jeepney-0.9.0-py3-none-any.whl (49 kB)\nDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\nDownloading nh3-0.2.22-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (777 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.7/777.7 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\nDownloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\nDownloading jaraco.classes-3.4.0-py3-none-any.whl (6.8 kB)\nDownloading jaraco.context-6.0.1-py3-none-any.whl (6.8 kB)\nDownloading jaraco_functools-4.2.1-py3-none-any.whl (10 kB)\nDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\nDownloading backports.tarfile-1.2.0-py3-none-any.whl (30 kB)\nDownloading more_itertools-10.7.0-py3-none-any.whl (65 kB)\nBuilding wheels for collected packages: SimpleWebSocketServer, typing, ushlex\ndone wheel for SimpleWebSocketServer (setup.py) ... \u001b[?25l\n\u001b[?25h  Created wheel for SimpleWebSocketServer: filename=SimpleWebSocketServer-0.1.2-py3-none-any.whl size=9710 sha256=246acf1a8998cf1b3d363a1d0188bec0d70751539700b21247acf98a7882c7e0\n  Stored in directory: /home/jovyan/.cache/pip/wheels/af/cb/9d/23ef01c9c26b978be6d29ed456d7348abd0e96b1563049bd63\ndone wheel for typing (setup.py) ... \u001b[?25l\n\u001b[?25h  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26365 sha256=7cf93c5d5f015b94ee97c1e17c753f46265fd770134bd81adf74f14aa7512865\n  Stored in directory: /home/jovyan/.cache/pip/wheels/7c/d0/9e/1f26ebb66d9e1732e4098bc5a6c2d91f6c9a529838f0284890\ndoneng wheel for ushlex (setup.py) ... \u001b[?25l\n\u001b[?25h  Created wheel for ushlex: filename=ushlex-0.99.1-py3-none-any.whl size=4435 sha256=1ea8a067d1d55485c0fc06ae7d46c62532287d5ca1891e51930be4cebb476cfe\n  Stored in directory: /home/jovyan/.cache/pip/wheels/fd/e4/80/4de44668798392eb2f5b24f0130df2f5d28b43cb256bf9c1f9\nSuccessfully built SimpleWebSocketServer typing ushlex\nInstalling collected packages: ushlex, SimpleWebSocketServer, typing, rfc3986, pyparsing, pillow, nh3, more-itertools, mdurl, kiwisolver, jeepney, fonttools, docutils, cycler, contourpy, backports.tarfile, requests-toolbelt, readme-renderer, matplotlib, markdown-it-py, jaraco.functools, jaraco.context, jaraco.classes, id, SecretStorage, rich, keyring, twine, pyloco, matplot\nSuccessfully installed SecretStorage-3.3.3 SimpleWebSocketServer-0.1.2 backports.tarfile-1.2.0 contourpy-1.3.2 cycler-0.12.1 docutils-0.21.2 fonttools-4.59.0 id-1.5.0 jaraco.classes-3.4.0 jaraco.context-6.0.1 jaraco.functools-4.2.1 jeepney-0.9.0 keyring-25.6.0 kiwisolver-1.4.8 markdown-it-py-3.0.0 matplot-0.1.9 matplotlib-3.10.3 mdurl-0.1.2 more-itertools-10.7.0 nh3-0.2.22 pillow-11.3.0 pyloco-0.0.139 pyparsing-3.2.3 readme-renderer-44.0 requests-toolbelt-1.0.0 rfc3986-2.0.0 rich-14.0.0 twine-6.1.0 typing-3.7.4.3 ushlex-0.99.1\nCollecting scikit-learn\n  Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\nRequirement already satisfied: numpy>=1.22.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from scikit-learn) (2.2.6)\nCollecting scipy>=1.8.0 (from scikit-learn)\n  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\nCollecting joblib>=1.2.0 (from scikit-learn)\n  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\nCollecting threadpoolctl>=3.1.0 (from scikit-learn)\n  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\nDownloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\nDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\nDownloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\nInstalling collected packages: threadpoolctl, scipy, joblib, scikit-learn\nSuccessfully installed joblib-1.5.1 scikit-learn-1.7.0 scipy-1.15.3 threadpoolctl-3.6.0\n"}],"execution_count":3},{"cell_type":"markdown","source":"<a name=\"p1\"></a>\n\n---\n## **Part 1: Breast Cancer Dataset**\n---\n\n#### **About the Dataset**\nBreast cancer is one of the most common types of cancer in women. Each year in the United States, about 264,000 women are diagnosed with breast cancer. The abilty to detect it early is extremely important. The following dataset is taken from the [UCI ML Breast Cancer Wisconsin (Diagnostic) dataset](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)). The dataset contains mammography exam results and whether or not cancer was detected.\n\nThe features are as follows:\n* `radius`\n* `texture`: standard deviation of gray-scale values\n* `perimeter`\n* `area`\n* `smoothness`: local variations in radius lengths\n* `compactness`: perimeter^2 / area - 1\n* `concavity`: severity of concave portions of the contour\n* `concave points`: number of concave portions of the contour\n* `symmetry`\n* `fractal dimension`: \"coastline approximation\" - 1\n\nNote: There is data recorded for the mean, standard error, and worst (or largest) for each feature, resulting in 30 total features.\n\n<br>\n\n#### **Your Task**\nUsing the Breast Cancer dataset, we will do the following:\n* Create a KNN classifier model that can be used to predict whether or not a patient has breast cancer.\n* Use the model to predict whether or not patient have breast cancer based on various mean radii and mean textures.\n\n<br>\n\n","metadata":{"id":"GJyKQAWMv8sR"}},{"cell_type":"markdown","source":"#### **Step #1: Load the data**\n\nLoad in the `Breast Cancer Dataset`. You may refer to this [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html).\n","metadata":{"id":"Sl7GlNcov8sk"}},{"cell_type":"code","source":"from sklearn.datasets import load_breast_cancer\n\ndata = load_breast_cancer()\n\ndata.keys()","metadata":{"id":"U3BGz5Bn-pV_","trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"#### **Step #2: Decide independent and dependent variables**\n\nComplete the cell below to select our features and label. In particular, we will fit our classifier using the `\"mean radius\"` and `\"mean texture\"` features in order to predict whether the patient has breast cancer.","metadata":{"id":"5twdSdPwv8sm"}},{"cell_type":"code","source":"features = df[# COMPLETE THIS CODE\nlabel = df[# COMPLETE THIS CODE","metadata":{"id":"HTcXl8htv8sn","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Before we continue our steps, let's visualize our data.**\n\nCreate a scatterplot that visualizes the correlation between your features.","metadata":{"id":"z7v4MpODv8so"}},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"mFKhqHVZ_MIT","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #3: Split data into training and testing data**","metadata":{"id":"l7xKAJAJv8so"}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = model_selection.train_test_split(features, label, test_size = .2, random_state=42) # COMPLETE THIS CODE","metadata":{"id":"z77noZidv8so","trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m model_selection\u001b[38;5;241m.\u001b[39mtrain_test_split(\u001b[43mfeatures\u001b[49m, label, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m) \u001b[38;5;66;03m# COMPLETE THIS CODE\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"],"ename":"NameError","evalue":"name 'features' is not defined","output_type":"error"}],"execution_count":22},{"cell_type":"markdown","source":"#### **Step #4: Import the KNN algorithm**\n\n**Run the code below to complete this step.**","metadata":{"id":"J2prquWav8so"}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","metadata":{"id":"kr38Jg-hv8so","trusted":true},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"#### **Step #5: Initialize the model and set hyperparameters**\n\n\nLet's set the *hyperparameter* `n_neighbors = 5`.","metadata":{"id":"_0jRPRihv8sp"}},{"cell_type":"code","source":"model = KNeighborsClassifier(n_neighbors = 5) # COMPLETE THIS CODE","metadata":{"id":"-pj-SSljv8sp","trusted":true},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"#### **Step #6: Fit your model and make predictions on the test set. Create a visualization if applicable.**","metadata":{"id":"xNX80Tywv8sp"}},{"cell_type":"code","source":"# COMPLETE THIS CODE\n\nmodel. fit(X train, y_train)\n\npred = model.predict(X_test)","metadata":{"id":"zsVEczjev8sp","trusted":true},"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[26], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    model. fit(X train, y_train)\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"],"ename":"SyntaxError","evalue":"invalid syntax. Perhaps you forgot a comma? (1426504790.py, line 3)","output_type":"error"}],"execution_count":26},{"cell_type":"markdown","source":"#### **Create a visualization**\n\n**Run the code below to visualize the decision boundary of this KNN model.**\n","metadata":{"id":"QIei-70av8sp"}},{"cell_type":"code","source":"# Make the same scatter plot of the training data\n\nfig, ax = plt.subplots(figsize=(10,6))\n\nxx, yy = np.meshgrid(np.arange(6, 30, 0.1),\n                     np.arange(6, 42, 0.1))\nz = model.predict(np.c_[xx.ravel(), yy.ravel()])\nz = z.reshape(xx.shape)\n\nax.pcolormesh(xx, yy, z, alpha=0.1)\n\nfor label, data in df.groupby('TARGET'):\n  ax.scatter(data[\"mean radius\"], data[\"mean texture\"], label=[\"Cancerous\",\"Healthy\"][label])\n\nax.set_title(\"Decision Boundary of the KNN Classifier\")\nax.set_xlabel(\"mean radius\")\nax.set_ylabel(\"mean texture\")\nax.legend()\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"outputId":"e92462b0-1223-40ab-8ab1-474f532f3260","id":"r6PtowtXv8sp","trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      5\u001b[0m xx, yy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m0.1\u001b[39m),\n\u001b[1;32m      6\u001b[0m                      np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m42\u001b[39m, \u001b[38;5;241m0.1\u001b[39m))\n\u001b[0;32m----> 7\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mc_[xx\u001b[38;5;241m.\u001b[39mravel(), yy\u001b[38;5;241m.\u001b[39mravel()])\n\u001b[1;32m      8\u001b[0m z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mreshape(xx\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     10\u001b[0m ax\u001b[38;5;241m.\u001b[39mpcolormesh(xx, yy, z, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"#### **Wait for your instructor to continue.**","metadata":{"id":"TE3mnT_Pv8ss"}},{"cell_type":"markdown","source":"#### **Step #7: Evaluate your model**\n\nPrint the accuracy and confusion matrix for your model's performance on the test set.\n\n<br>\n\n**NOTE**: Here you can use `[\"Cancerous\",\"Healthy\"]` for the `display_labels` argument.","metadata":{"id":"w-dQxm5Fv8ss"}},{"cell_type":"code","source":"print(\"Accuracy Score: \" # COMPLETE THIS CODE","metadata":{"id":"MNAYTrzUv8su","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics.ConfusionMatrixDisplay.from_predictions(# COMPLETE THIS CODE","metadata":{"id":"cxquOZx5v8su","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #8: Use the model**\n\nPredict whether the following patients have cancer or not:\n\n1. Is a patient with mean radius `15.5` and mean texture `31.2` likely to have cancer?\n2. Is a patient with mean radius `12.2` and mean texture `34.5` likely to have cancer?\n\n","metadata":{"id":"NDdTaGE_v8su"}},{"cell_type":"code","source":"patient1 = pd.DataFrame([[15.5, 31.2]], columns=[\"mean radius\", \"mean texture\"])\n\nprediction1 = model.predict(patient1) [0] # COMPLETE THIS CODE\n\nprint(\"Patient 2 \" + str(['is likely', 'is not likely'][prediction2]) + \" to have cancer\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f96e762-7dbb-4236-c66b-0abb67131a2a","id":"NaDHn0zav8su","trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m patient1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([[\u001b[38;5;241m15.5\u001b[39m, \u001b[38;5;241m31.2\u001b[39m]], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean radius\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean texture\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m prediction1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(patient1) [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# COMPLETE THIS CODE\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatient 2 \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis likely\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not likely\u001b[39m\u001b[38;5;124m'\u001b[39m][prediction2]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to have cancer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}],"execution_count":18},{"cell_type":"code","source":"patient2 = pd.DataFrame([[12.2,34.5]], columns = [\"means radius\", \"mean texture\"])# COMPLETE THIS CODE\n\nprediction2 = model.predict(patient2)[0] # COMPLETE THIS CODE\n\nprint(\"Patient 2 \" + str(['is likely', 'is not likely'][prediction2]) + \" to have cancer\")","metadata":{"id":"zTrrPGw0v8su","trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m patient2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([[\u001b[38;5;241m12.2\u001b[39m,\u001b[38;5;241m34.5\u001b[39m]], columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeans radius\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean texture\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;66;03m# COMPLETE THIS CODE\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m prediction2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(patient2)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# COMPLETE THIS CODE\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPatient 2 \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis likely\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not likely\u001b[39m\u001b[38;5;124m'\u001b[39m][prediction2]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to have cancer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}],"execution_count":19},{"cell_type":"markdown","source":"### **Reflection question**\nAnswer the following question: In the case of predicting breast cancer, do you think it's more important to reduce false positives or false negatives?","metadata":{"id":"GVPL2dHCW_Dj"}},{"cell_type":"markdown","source":"### **Hyperparameter Tuning [OPTIONAL]**\n\nRun the given code below to find the optimal k for our model. What is this k?","metadata":{"id":"wVQU5DEggnZK"}},{"cell_type":"code","source":"# Now lets see how accurate it is looking at all 30 variables\n\n# Load all columns of the dataset\nX_train, X_test, y_train, y_test = model_selection.train_test_split(df.drop(columns='TARGET'), df[['TARGET']],\n                                      test_size=0.2, random_state=42)\n\n# Hyperparameter tuning\nscores = {}\nfor n in range(1,50,2):\n    full_model = KNeighborsClassifier(n_neighbors = n)\n    full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n    pred = full_model.predict(X_test)\n    score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n    scores[n] = score\n\n\nplt.title(\"Accuracy on Test set across Hyperparameter values\")\nprint(scores)\nplt.plot(list(scores.keys()), list(scores.values()), label = 'Scores for all K')\n\n# ADDING THE PERFORMANCE FOR K = SQRT SIZE FOR REFERENCE\nk = int(len(X_train)**(1/2)/2)*2 - 1\nfull_model = KNeighborsClassifier(n_neighbors = k)\nfull_model.fit(X_train, y_train.to_numpy().reshape(-1))\npred = full_model.predict(X_test)\nscore = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\nplt.scatter([k], [score], color = 'r', marker = '*', s = 200, label = 'Square Root of Training Data Size')\n\n\ntop_score = max(scores.values())\nbest_k = list(scores.keys())[list(scores.values()).index(top_score)]\nplt.scatter([best_k], [top_score], color = 'g', marker = '*', s = 200, label = 'Best Perfomance')\n\nplt.legend()\nplt.show()\n\n\n\n# PRINTING THE RESULTS\nprint(\"Top score of optimal classifier: \" + str(top_score))\nprint(\"Best Value of K to use \" + str(best_k))","metadata":{"id":"bLEGaoyggnZK","colab":{"base_uri":"https://localhost:8080/","height":524},"outputId":"05c0c96a-629c-4d82-fca9-1e7ca7a7535f","trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Now lets see how accurate it is looking at all 30 variables\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load all columns of the dataset\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m model_selection\u001b[38;5;241m.\u001b[39mtrain_test_split(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTARGET\u001b[39m\u001b[38;5;124m'\u001b[39m), df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTARGET\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[1;32m      5\u001b[0m                                       test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Hyperparameter tuning\u001b[39;00m\n\u001b[1;32m      8\u001b[0m scores \u001b[38;5;241m=\u001b[39m {}\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"],"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error"}],"execution_count":10},{"cell_type":"markdown","source":"<a name=\"p2\"></a>\n\n---\n## **Part 2: Spotify Dataset**\n---\n#### **About the Dataset**\nSpotify is one of the most popular digital music streaming services with over 515 million monthly users. The following dataset from Spotify data looks at different qualities of songs like energy, key, loudness, and tempo to see if a song is a top or bottom hit.\n\nThe features are as follows:\n* `artist`: song artist(s)\n* `song`: song title\n* `duration_ms`: the track length in milliseconds (ms)\n* `year`: the year the song was released\n* `top half`: whether or not the song is in the top half of hits\n* `danceability`: how suitable a track is for dancing (0.0: least danceable, 1.0: most danceable)\n* `energy`: perceptual measure of intensity and activity (0.0 - 1.0)\n* `key`: the key the track is in; integers map to pitches using standard Pitch Class notation (0: C, 1: C♯/D♭, 2:D, ..., 11: B)\n* `loudness`: the overall loudness of a track in decibels (dB)\n* `mode`: the modality of a track, or the type of scale from which its melodic content is derived (0: minor, 1: major)\n* `speechiness`: a measure of the presence of spoken words in the track (0-0.33: music and other non-speech-like tracks, 0.33-0.66: contain both music and speech, 0.66-1.0: most likely made entirely of spoken words (e.g. talk show, audio book, poetry))\n* `acousticness`: a confidence measure of whether or not the track is acoustic (0.0: low confidence, 1.0: high confidence)\n* `instrumentalness`: predicts whether or not a track contains vocals (0.0: vocal content, 1.0: no vocal content)\n* `liveness`: detects the presence of an audience in the recording ( > 0.8: strong likelihood the track was performed live)\n* `valence`: musical positiveness conveyed by the track (lower valence: more negative, higher valence: more positive)\n* `tempo`: the overall estimated tempo in beats per minute (BPM)\n* `genre`: the genre in which the track belongs\n* `explicit`: whether or not the song is explicit\n* `explicity binary`: whether or not the song is explicit (0: no, 1: yes)\n\n<br>\n\n#### **Your Task**\nUsing the Spotify dataset, you will do the following:\n* Create a KNN model that can predict whether a song will be a hit or a bust;\n* Predict whether songs with various keys and energies will be hits or busts.","metadata":{"id":"KYR-x1kwlVJL"}},{"cell_type":"markdown","source":"#### **Step #1: Load the data**\n","metadata":{"id":"TPZneE0f5EPC"}},{"cell_type":"code","source":"url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vQJ9UIsI2j8vPnefdBj6GIrUGiDMsF5HRVAg4rsfaZqX5fAoTGLGydLvPXPQvE5ZSo9_aet1SC5UQji/pub?gid=1132556054&single=true&output=csv\"\nspotify_dy = pd.read_csv(url)\n\nspotify_dy.head ()\n\n# COMPLETE THIS CODE","metadata":{"id":"TO6Vymh7_bsH","trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"           artist                    song  duration_ms  year  top half  \\\n0  Britney Spears  Oops!...I Did It Again       211160  2000         1   \n1       blink-182    All The Small Things       167066  1999         1   \n2      Faith Hill                 Breathe       250546  1999         1   \n3        Bon Jovi            It's My Life       224493  2000         1   \n4          *NSYNC             Bye Bye Bye       200560  2000         1   \n\n   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n0         0.751   0.834    1    -5.444     0       0.0437        0.3000   \n1         0.434   0.897    0    -4.918     1       0.0488        0.0103   \n2         0.529   0.496    7    -9.007     1       0.0290        0.1730   \n3         0.551   0.913    0    -4.063     0       0.0466        0.0263   \n4         0.614   0.928    8    -4.806     0       0.0516        0.0408   \n\n   instrumentalness  liveness  valence    tempo         genre  explicit  \\\n0          0.000018    0.3550    0.894   95.053           pop     False   \n1          0.000000    0.6120    0.684  148.726     rock, pop     False   \n2          0.000000    0.2510    0.278  136.859  pop, country     False   \n3          0.000013    0.3470    0.544  119.992   rock, metal     False   \n4          0.001040    0.0845    0.879  172.656           pop     False   \n\n   explicity binary  \n0                 0  \n1                 0  \n2                 0  \n3                 0  \n4                 0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>artist</th>\n      <th>song</th>\n      <th>duration_ms</th>\n      <th>year</th>\n      <th>top half</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>genre</th>\n      <th>explicit</th>\n      <th>explicity binary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Britney Spears</td>\n      <td>Oops!...I Did It Again</td>\n      <td>211160</td>\n      <td>2000</td>\n      <td>1</td>\n      <td>0.751</td>\n      <td>0.834</td>\n      <td>1</td>\n      <td>-5.444</td>\n      <td>0</td>\n      <td>0.0437</td>\n      <td>0.3000</td>\n      <td>0.000018</td>\n      <td>0.3550</td>\n      <td>0.894</td>\n      <td>95.053</td>\n      <td>pop</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>blink-182</td>\n      <td>All The Small Things</td>\n      <td>167066</td>\n      <td>1999</td>\n      <td>1</td>\n      <td>0.434</td>\n      <td>0.897</td>\n      <td>0</td>\n      <td>-4.918</td>\n      <td>1</td>\n      <td>0.0488</td>\n      <td>0.0103</td>\n      <td>0.000000</td>\n      <td>0.6120</td>\n      <td>0.684</td>\n      <td>148.726</td>\n      <td>rock, pop</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Faith Hill</td>\n      <td>Breathe</td>\n      <td>250546</td>\n      <td>1999</td>\n      <td>1</td>\n      <td>0.529</td>\n      <td>0.496</td>\n      <td>7</td>\n      <td>-9.007</td>\n      <td>1</td>\n      <td>0.0290</td>\n      <td>0.1730</td>\n      <td>0.000000</td>\n      <td>0.2510</td>\n      <td>0.278</td>\n      <td>136.859</td>\n      <td>pop, country</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bon Jovi</td>\n      <td>It's My Life</td>\n      <td>224493</td>\n      <td>2000</td>\n      <td>1</td>\n      <td>0.551</td>\n      <td>0.913</td>\n      <td>0</td>\n      <td>-4.063</td>\n      <td>0</td>\n      <td>0.0466</td>\n      <td>0.0263</td>\n      <td>0.000013</td>\n      <td>0.3470</td>\n      <td>0.544</td>\n      <td>119.992</td>\n      <td>rock, metal</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>*NSYNC</td>\n      <td>Bye Bye Bye</td>\n      <td>200560</td>\n      <td>2000</td>\n      <td>1</td>\n      <td>0.614</td>\n      <td>0.928</td>\n      <td>8</td>\n      <td>-4.806</td>\n      <td>0</td>\n      <td>0.0516</td>\n      <td>0.0408</td>\n      <td>0.001040</td>\n      <td>0.0845</td>\n      <td>0.879</td>\n      <td>172.656</td>\n      <td>pop</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"#### **Step #2: Decide independent and dependent variables**\n\nFor this problem, we are interested in how the `key` and `energy` affect whether or not a song becomes a hit.","metadata":{"id":"H7FdHFQh5Hu8"}},{"cell_type":"code","source":"features = spotify_df[# COMPLETE THIS CODE\nlabel = spotify_df[# COMPLETE THIS CODE\n\nplt.figure(figsize=(10,6))\nplt.scatter(# COMPLETE THIS CODE\n\n# yellow: top hit, purple: bottom hit\nplt.title(\"Energy vs. Key of Hit Songs Colored by Whether they were a Top or Bottom Hit\")\nplt.xlabel(\"Key\")\nplt.ylabel(\"Energy\")\n\nplt.show()","metadata":{"id":"dRxe-es59l3t","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #3: Split data into training and testing data**\n\nSplit the data as described above.","metadata":{"id":"8utEQrU558Xw"}},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"2Kdf8XXMdIrr","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #4: Import the KNN algorithm**","metadata":{"id":"CvENbkqU562F"}},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"-3JRpVw3dUpH","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #5: Initialize the model and set hyperparameters**\n\nLet's set the *hyperparameter* `n_neighbors = 1`.","metadata":{"id":"Mk8ZPWRJ6Hrq"}},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"fRDPWV3EdVhe","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #6: Fit your model and make a prediction. Create a visualization if applicable.**","metadata":{"id":"3He9SfO86NvK"}},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"zJZ4gQ0rgoJs","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Create a visualization**\n\n**Run the code below to visualize the decision boundary of this KNN model.**\n","metadata":{"id":"SWSoWSi5-gX4"}},{"cell_type":"code","source":"# Make the same scatter plot of the training data\n!pip install spotify \n\nfig, ax = plt.subplots(figsize=(10,6))\n\nxx, yy = np.meshgrid(np.arange(spotify_df['key'].min() - 1, spotify_df['key'].max() + 1, 0.1),\n                     np.arange(spotify_df['energy'].min() - 0.1, spotify_df['energy'].max() + 0.1, 0.1))\nz = model.predict(np.c_[xx.ravel(), yy.ravel()])\nz = z.reshape(xx.shape)\n\nax.pcolormesh(xx, yy, z, alpha=0.1)\n\nfor label, data in spotify_df.groupby('top half'):\n  ax.scatter(data[\"key\"], data[\"energy\"], label=['lower half', 'top half'][label])\n\nax.set_title(\"Decision Boundary of the KNN Classifier\")\nax.set_xlabel(\"Key\")\nax.set_ylabel(\"Energy\")\nax.legend()\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"outputId":"01a82067-2e28-4b3a-ebb3-5926bf01e378","id":"XMRHsvj4-gX5","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Collecting spotify\n  Downloading spotify-0.10.2-py3-none-any.whl.metadata (5.5 kB)\nCollecting aiohttp<4.0,>=3.6 (from spotify)\n  Downloading aiohttp-3.12.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\nCollecting backoff<2.0.0,>=1.10.0 (from spotify)\n  Downloading backoff-1.11.1-py2.py3-none-any.whl.metadata (12 kB)\nCollecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0,>=3.6->spotify)\n  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\nCollecting aiosignal>=1.4.0 (from aiohttp<4.0,>=3.6->spotify)\n  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\nCollecting async-timeout<6.0,>=4.0 (from aiohttp<4.0,>=3.6->spotify)\n  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\nRequirement already satisfied: attrs>=17.3.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from aiohttp<4.0,>=3.6->spotify) (25.1.0)\nCollecting frozenlist>=1.1.1 (from aiohttp<4.0,>=3.6->spotify)\n  Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nCollecting multidict<7.0,>=4.5 (from aiohttp<4.0,>=3.6->spotify)\n  Downloading multidict-6.6.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\nCollecting propcache>=0.2.0 (from aiohttp<4.0,>=3.6->spotify)\n  Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nCollecting yarl<2.0,>=1.17.0 (from aiohttp<4.0,>=3.6->spotify)\n  Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\nRequirement already satisfied: typing-extensions>=4.2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from aiosignal>=1.4.0->aiohttp<4.0,>=3.6->spotify) (4.12.2)\nRequirement already satisfied: idna>=2.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0,>=3.6->spotify) (3.10)\nDownloading spotify-0.10.2-py3-none-any.whl (46 kB)\nDownloading aiohttp-3.12.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\nDownloading backoff-1.11.1-py2.py3-none-any.whl (13 kB)\nDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\nDownloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\nDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\nDownloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\nDownloading multidict-6.6.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\nDownloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\nDownloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\nInstalling collected packages: propcache, multidict, frozenlist, backoff, async-timeout, aiohappyeyeballs, yarl, aiosignal, aiohttp, spotify\nSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 async-timeout-5.0.1 backoff-1.11.1 frozenlist-1.7.0 multidict-6.6.3 propcache-0.3.2 spotify-0.10.2 yarl-1.20.1\n"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install spotify\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m xx, yy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(np\u001b[38;5;241m.\u001b[39marange(\u001b[43mspotify_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, spotify_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m),\n\u001b[1;32m      7\u001b[0m                      np\u001b[38;5;241m.\u001b[39marange(spotify_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.1\u001b[39m, spotify_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m))\n\u001b[1;32m      8\u001b[0m z \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mc_[xx\u001b[38;5;241m.\u001b[39mravel(), yy\u001b[38;5;241m.\u001b[39mravel()])\n\u001b[1;32m      9\u001b[0m z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mreshape(xx\u001b[38;5;241m.\u001b[39mshape)\n","\u001b[0;31mNameError\u001b[0m: name 'spotify_df' is not defined"],"ename":"NameError","evalue":"name 'spotify_df' is not defined","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"#### **Step #7: Evaluate your model**\n\nPrint the accuracy and confusion matrix for your model's performance on the test set.\n\n<br>\n\n**NOTE**: You can use `['top half', 'bottom half']` for the `display_labels` argument here.","metadata":{"id":"zlMCxDa_-W1f"}},{"cell_type":"code","source":"print(\"Accuracy Score: \" + # COMPLETE THIS CODE","metadata":{"id":"rbsBftHbFpUT","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics.ConfusionMatrixDisplay.from_predictions(# COMPLETE THIS CODE","metadata":{"id":"x8W9uuTe-W1g","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #8: Use the model**\n\nUse your model to predict whether the following songs are in the top hits.\n\n1. We are given an song with `key = 3` and `energy = 0.8`. According to your KNN model, will this song be in the top half of hits?\n2. We are given another song with `key = 4.5` and `energy = 0.45`. Will this song be a bust or a hit?\n3. We are given an song with `key = 1` and `energy = 0.5`. Will this song be a bust or a hit?","metadata":{"id":"sj2QnHkE7J9E"}},{"cell_type":"code","source":"song = pd.DataFrame([[3, 0.8]], columns = [\"key\", \"energy\"])\nprediction = # COMPLETE THIS CODE\nprint(prediction)","metadata":{"id":"FFlpDpjwz0BP","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"Owgkh7viFwRE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"8dXQz9UYFwIJ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Reflection question**\nAnswer the following question: Do you think using only the two features `energy` and `key` is enough to predict whether or not a song will be a top hit?","metadata":{"id":"hVzquV13hgFj"}},{"cell_type":"markdown","source":"### **Hyperparameter Tuning [OPTIONAL]**\n\nRun the given code below to find the optimal k for our model. What is this k?","metadata":{"id":"AYjkYKWK_0HT"}},{"cell_type":"code","source":"# Hyperparameter tuning\nscores = {}\nfor n in range(1,50,2):\n    full_model = KNeighborsClassifier(n_neighbors = n)\n    full_model.fit(X_train, y_train.to_numpy().reshape(-1))\n    pred = full_model.predict(X_test)\n    score = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\n    scores[n] = score\n\n\nplt.title(\"Accuracy on Test set across Hyperparameter values\")\nprint(scores)\nplt.plot(list(scores.keys()), list(scores.values()), label = 'Scores for all K')\n\n# ADDING THE PERFORMANCE FOR K = SQRT SIZE FOR REFERENCE\nk = int(len(X_train)**(1/2)/2)*2 - 1\nfull_model = KNeighborsClassifier(n_neighbors = k)\nfull_model.fit(X_train, y_train.to_numpy().reshape(-1))\npred = full_model.predict(X_test)\nscore = sum(pred == y_test.to_numpy().reshape(-1))/len(pred)* 100\nplt.scatter([k], [score], color = 'r', marker = '*', s = 200, label = 'Square Root of Training Data Size')\n\n\ntop_score = max(scores.values())\nbest_k = list(scores.keys())[list(scores.values()).index(top_score)]\nplt.scatter([best_k], [top_score], color = 'g', marker = '*', s = 200, label = 'Best Perfomance')\n\nplt.legend()\nplt.show()\n\n\n\n# PRINTING THE RESULTS\nprint(\"Top score of optimal classifier: \" + str(top_score))\nprint(\"Best Value of K to use \" + str(best_k))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":524},"outputId":"11300b1a-1a29-4a02-857b-bd0ee59cc0db","id":"QKhp6DIm_0HY","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a name=\"p3\"></a>\n\n---\n## **Part 3: Australia Dataset**\n---\n#### **About the Dataset**\nWeather and humans' ability to forecast/predict it play a large role in many aspects of daily life. This dataset contains about 10 years of daily weather observations from numerous Australian weather stations.\n\nThe features are as follows:\n* `Location`: the location of the weather station\n* `WindSpeed`: the wind speed averaged over 10 minutes prior to 9am (in km/hr)\n* `Humidity`: the humidity (percent) at 9am\n* `Pressure`: atmospheric pressure reduced to mean sea level at 9am (in hundreds of hPa)\n* `Temp`: temperature at 9am (in Celsius)\n* `RainToday`: whether or not the rain/precipitation in the 24 hours to 9am exceeds 1mm (0: no, 1: yes)\n* `RainTomorrow`: whether or not it rained at least 1mm the next day (0: no, 1: yes)\n\n<br>\n\n#### **Your Task**\n* Build a model that can predict whether or not it will rain tomorrow.\n* Build another model with the optimal hyperparameters and compare the accuracies.\n\n\n<br>\n\n**Load the code below before continuing.**","metadata":{"id":"WBx3-jiP0zdL"}},{"cell_type":"code","source":"url = \"https://raw.githubusercontent.com/the-codingschool/TRAIN/main/australia/australia_weather.csv\"\n\n# COMPLETE THIS CODE","metadata":{"id":"dz7fW61r_hsO","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Problem #3.1**\n\nCreate a KNN model with the hyperparameter `n_neighbors = 3` in order to predict whether or not it will rain tomorrow. Use all features except `Location` and `RainTomorrow`, and then train and evaluate the model using `accuracy_score` and the confusion matrix.","metadata":{"id":"-YyuS71I_8Hu"}},{"cell_type":"code","source":"features = australia_df.drop(['Location', 'RainTomorrow'], axis=1)\nlabel = australia_df['RainTomorrow']\n\n#split the train and test data\n# COMPLETE THIS CODE\n\n# import the KNN algorithm\n# COMPLETE THIS CODE\n\n# initialize\n# COMPLETE THIS CODE\n\n# fit\n# COMPLETE THIS CODE\n\n# predict\n# COMPLETE THIS CODE\n\n# Evaluation of accuracy\nprint(\"Accuracy Score: \" + str(metrics.accuracy_score(# COMPLETE THIS CODE","metadata":{"id":"EGtbCrPm0zde","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics.ConfusionMatrixDisplay.from_predictions(# COMPLETE THIS CODE","metadata":{"id":"IG93bpOmrEHH","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics.ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)","metadata":{"id":"LOnuhW89r04Q","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a name=\"p4\"></a>\n\n---\n## **Part 4: [OPTIONAL] Homework Practice**\n---","metadata":{"id":"c69ICzzToxDC"}},{"cell_type":"markdown","source":"<a name=\"p4.1\"></a>\n\n---\n### **Part 4.1: Zoo Animal Classification Dataset**\n---\n\n#### **About the Dataset**\nThe following dataset contains information on various zoo animals, including their characteristics and classifications. Our goal is to build a model that predicts the classification of an animal based on its features.\n\n<br>\n\nThe labels you will be trying to predict are as follows:\n\n* `1` -- **Mammals** (41 animals in this category): aardvark, antelope, bear, boar, buffalo, calf, cavy, cheetah, deer, dolphin, elephant, fruitbat, giraffe, girl, goat, gorilla, hamster, hare, leopard, lion, lynx, mink, mole, mongoose, opossum, oryx, platypus, polecat, pony, porpoise, puma, cat, raccoon, reindeer, seal, sealion, squirrel, vampire, vole, wallaby, wolf.\n* `2` -- **Birds** (20 animals in this category): chicken, crow, dove, duck, flamingo, gull, hawk, kiwi, lark, ostrich, parakeet, penguin, pheasant, rhea, skimmer, skua, sparrow, swan, vulture, wren.\n* `3` -- **Reptiles** (5 animals in this category): pitviper, seasnake, slowworm, tortoise, tuatara.\n* `4` -- **Fish** (13 animals in this category): bass, carp, catfish, chub, dogfish, haddock, herring, pike, piranha, seahorse, sole, stingray, tuna.\n* `5` -- **Amphibians** (4 animals in this category): frog, frog, newt, toad.\n* `6` -- **Insects** (8 animals in this category): flea, gnat, honeybee, housefly, ladybird, moth, termite, wasp.\n* `7` -- **Invertebrates** (10 animals in this category): clam, crab, crayfish, lobster, octopus, scorpion, seawasp, slug, starfish, worm.\n\n<br>\n\nThe features are as follows (all features marked with an * is 1 if yes and 0 if no):\n\n\n* `animal_name`: Name of the animal\n* `hair`: Hair presence*\n* `feathers`: Feather presence*\n* `eggs`: Egg-laying ability*\n* `milk`: Milk production ability*\n* `airborne`: Ability to fly*\n* `aquatic`: Ability to live in water*\n* `predator`: Predatory behavior*\n* `toothed`: Teeth presence*\n* `backbone`: Backbone presence*\n*  `breathes`: Ability to breathe*\n* `venomous`: Venom presence*\n* `fins`: Fin presence*\n* `legs`: Number of legs (0, 2, 4, 5, 6, or 8)\n* `tail`: Tail presence*\n* `domestic`: Domestication status*\n* `catsize`: Cat-like size*\n* `class_type`: Numeric class identifier (1-7) as described above","metadata":{"id":"2I1Jg2wSymZf"}},{"cell_type":"markdown","source":"#### **Step #1: Load the data**\n\n","metadata":{"id":"uALsY1jv0OtU"}},{"cell_type":"code","source":"url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/zoo/zoo.data\"'\n\n# COMPLETE THIS CODE","metadata":{"id":"LJf1sXiS_uHi","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #2: Decide independent and dependent variables**\n\nYour goal is to predict `class_type` using all possible *numerical* features.\n","metadata":{"id":"5DJtkoHn0bL8"}},{"cell_type":"code","source":"features = # COMPLETE THIS CODE\nlabel = # COMPLETE THIS CODE","metadata":{"id":"f7-0cUep0naJ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #3: Split data into training and testing data**","metadata":{"id":"5omgCtfW1i4U"}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = # COMPLETE THIS CODE","metadata":{"id":"uE_3S_vw1mIr","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #4: Import your model**","metadata":{"id":"rrBakbiK1qGv"}},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"0-KRBRBN1s3W","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #5: Initialize your model and set hyperparameters**\n\nInitialize the KNN model, and set hyperparameter `n_neighbors = 3`.","metadata":{"id":"EEBL8QJ811ZN"}},{"cell_type":"code","source":"model = # COMPLETE THIS CODE","metadata":{"id":"qPq8Sokb167W","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #6: Fit your model, test on the testing data**\n\n**NOTE**: Visualization would be quite tricky here since there are 16 features instead of just 2. So, do not worry about doing this here.","metadata":{"id":"xTpPtWDz1-YZ"}},{"cell_type":"code","source":"model.# COMPLETE THIS CODE\npred = # COMPLETE THIS CODE","metadata":{"id":"J7s6t9fF2BnG","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #7: Evaluate your model**\n\nPrint the accuracy and confusion matrix for your model's performance on the test set.\n\n<br>\n\n**NOTE**: In this case, the labels are already the names of the classes as opposed to less meaningful numbers, so you do not need to supply a `display_labels` argument.","metadata":{"id":"HZbsJfYtGQz2"}},{"cell_type":"code","source":"print(\"Accuracy Score: \", # COMPLETE THIS CODE","metadata":{"id":"YCYWHxhiGQz3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics.ConfusionMatrixDisplay.from_predictions(# COMPLETE THIS CODE","metadata":{"id":"JppmTSVoGQz3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a name=\"p4.2\"></a>\n\n---\n### **Part 4.2: Classifying Stars**\n---\nIn this Part, we will use a dataset that contains data collected by astronomers about different classes of stars that have been observed. With KNN, you will use the size and temperature of stars to determine which class they may be from the following:\n\n* `0`: Red Dwarf\n* `1`: Brown Dwarf\n* `2`: White Dwarf\n* `3`: Main Sequence\n* `4`: SuperGiants\n* `5`: HyperGiants","metadata":{"id":"UxfdmNbVmJuq"}},{"cell_type":"markdown","source":"#### **Step \\#1: Load the data**\n\n","metadata":{"id":"aCFtCV4tmJu0"}},{"cell_type":"code","source":"url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTCZgoegOHa49SFXYU-ZZTdCkgTp0sneU1BsEOa7vusjTXPPLcn0i3kXhX1nyqkApJHCKTkw0mWuWr4/pub?gid=753880827&single=true&output=csv'\n\n# COMPLETE THIS CODE","metadata":{"id":"aLfL64KK_0Kh","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step \\#2: Decide independent and dependent variables**\n\nUse the dataframe `stars_df` and subset your data into `inputs` and `output`.\n\n<br>\n\nThe `inputs` will be `size` and `temperature`.\n\nThe `output` will be `class`.","metadata":{"id":"w0fsjaktmJu0"}},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"pIGykhmeQzf7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step \\#3: Split data into train and test data**\n\nLet's split your data into training and testing data. Since this is a small dataset, let's just reserve 10% of the data for testing.","metadata":{"id":"A6ij7uTDmJu1"}},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"piz2rHXbQvcS","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step \\#4: Import your model**\n","metadata":{"id":"nAl_9jbkmJu1"}},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"66liNofsQuu6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step \\#5: Initialize your model and set hyperparameters**\n\nBuild your model with $K=7$.","metadata":{"id":"dSFm8SYpmJu1"}},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"FDufCenCQt8m","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step \\#6: Fit your model and make a prediction**\n\nTrain your model with the `x_train` and `y_train` training data and make predictions on `x_test`.","metadata":{"id":"mtBikiJdmJu1"}},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"9gZS2U1aQrh9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Create a visualization**\n\n**Run the code below to visualize the decision boundary of this KNN model.**\n","metadata":{"id":"Aa9e44fqnnf7"}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,6))\n\nxx, yy = np.meshgrid(np.arange(0, 2000, 10),\n                     np.arange(1900, 40000, 100))\nz = knn_model.predict(np.c_[xx.ravel(), yy.ravel()])\nz = z.reshape(xx.shape)\n\nax.pcolormesh(xx, yy, z, alpha=0.1)\n\nlabels = ['Red Dwarf', 'Brown Dwarf', 'White Dwarf', 'Main Sequence', 'SuperGiants', 'HyperGiants']\nfor label, data in stars_df.groupby('class'):\n  ax.scatter(data[\"size\"], data[\"temperature\"], label=labels[label])\n\nax.set_title(\"Decision Boundary of the KNN Classifier\")\nax.set_xlabel(\"Star Size\")\nax.set_ylabel(\"Star Temperature\")\nax.legend()\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"outputId":"4d1e7ced-30e9-4719-d142-b79317eb192b","id":"6EtBQwK1nnf7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #7: Evaluate your model**\n\nPrint the accuracy and confusion matrix for your model's performance on the test set.\n\n<br>\n\n**NOTE**: It's not necessary to supply a `display_labels` argument, but if you are curious see if you can use the information provided in this Part to supply them.","metadata":{"id":"GWLwxZhIQDTM"}},{"cell_type":"code","source":"print(\"Accuracy Score: \", # COMPLETE THIS CODE","metadata":{"id":"dMfXJWG0QDTN","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics.ConfusionMatrixDisplay.from_predictions(# COMPLETE THIS CODE","metadata":{"id":"mcHyqz5cQDTN","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step \\#8: Make predictions**\n\n\nAstronomers have heard of your amazing ML model for predicting star types and want you to help them categorize new stars they have observed! For each problem below, use your KNN model to classify the stars based on the data given to you.\n\n\n1. `size`: 708.9, `temperature`: 12100 (`[708.9, 12100]`)\n\n2. `size`: 0.0998, `temperature`:  3484 (`[0.0998, 3484]`)\n\n3. `size`: 6.39, `temperature`:  34190 (`[6.39, 34190]`)\n\n4. `size`: 0.16, `temperature`: 2799 (`[0.16, 2799]`)","metadata":{"id":"kGoZURsgmJu1"}},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"U7b0UAlTQmvz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"QH6aPxM3Qpkp","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"LShnE8d-QpbB","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"QVW-ZPYoQpM-","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a name=\"p4.3\"></a>\n\n---\n### **Part 4.3: RGB Color Classification Dataset**\n---\n\nVisible colors of light (for humans) and digital colors can be represented in the form of RGB values. The **RGB color model** operates as an additive system where <font color=\"red\">red</font>, <font color=\"green\">green</font>, and <font color=\"#2964f0\">blue</font> (**<font color=\"red\">R</font><font color=\"green\">G</font><font color=\"#2964f0\">B</font>**) primary light colors combine in diverse ways to replicate a wide spectrum of colors.\n\nEach of these primary colors is represented by an integer value between 0 and 255 (just under 256 or 2<sup>8</sup> on the binary number scale). A lower value means a lower intensity or darker color. Likewise, an RGB of (0, 0, 0) is black, while (255, 255, 255) is white. The closer the red, green, and blue values are to being equal, the more likely a color is to appear gray. For example, RGB(113, 113, 113) and RGB(207, 207, 207) are different shades of gray.\n\nWithout checking, what color would RGB(172, 145, 236) be? <br />That's a tough question to answer!\n\nNaturally, we as humans often use names to describe colors as we see them. You may have grown up using crayons with names like *scarlet*, *dark purple*, or *yellow-orange*. But where is the line between *orange* and *yellow* drawn? Classifying colors under an umbrella label can be difficult and is often individually or even culturally subjective! This task becomes even more challenging for those with a form of color blindness.\n\nBeyond the commonly known groupings of primary, secondary, and tertiary colors, [research](https://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC1618485&blobtype=pdf) has found an optimitzed set of 11 distinct color categories for classification: <br />\n> *Red, Orange, Yellow, Green, Blue, Purple, Pink, Brown, Black, Gray, White*\n\n\n<br />\n\n---\n\n#### **About the Dataset**\n\nThis dataset contains 5053 RGB color samples that have been labelled into one of 11 different categories.\n\nThis **[Google Color Picker](https://www.google.com/search?rls=en&q=color+picker)** may be a handy tool to use throughout this section!\n\nThe features are as follows:\n\n- `red` - RGB red value ( integer 0-255 )\n\n- `green` - RGB green value ( integer 0-255 )\n\n- `blue` - RGB blue value ( integer 0-255 )\n\n- `label` - color category, there are 11 total:\n\n    - *Red, Orange, Yellow, Green, Blue, Purple, Pink, Brown, Black, Gray, White*\n\n\n<br>\n\n#### **Your Task**\nUsing the RGB Color Classification dataset, you will do the following:\n* Create a KNN model that can predict the categorization of a color based on its red, green, and blue values.\n* Plot and compare the results and make note of your findings.\n","metadata":{"id":"LHaoB5X9GIzo"}},{"cell_type":"markdown","source":"#### **Step #1: Load the data**\n\n","metadata":{"id":"Hn0cpJ4KG4I4"}},{"cell_type":"code","source":"url = \"https://raw.githubusercontent.com/the-codingschool/TRAIN/main/color_classification/color_data.csv\"\n\n# COMPLETE THIS CODE","metadata":{"id":"gAaPQol5_6tU","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #2: Create visualizations to get familiar with the data**\n\nFirst, create either a bar graph or histogram to visualize the distribution of color categories in the dataset.\n\nChallenge: If you can, try to color the bars the same as the corresponding label.","metadata":{"id":"p-SRaUwf0_NJ"}},{"cell_type":"code","source":"colors = list(rgb_df['label'].unique())\ntotal_num_of_each_color = [rgb_df['label'].value_counts()[c] for c in colors]\n\nplt.axes().set_facecolor('lightgray')\nplt.bar(# COMPLETE THIS CODE\n\n# COMPLETE THIS CODE - axis labels","metadata":{"id":"C3ODy_9mOrev","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nSince there are three separate values that make up an RGB color, let's use a **3D scatter plot** to visualize the spread of the data. We can color the points with either their color label or with the actual RGB hue if we condense the three values into a single representation.\n\n- **`make_hex()`** - Takes a dataframe row (with the features ['red', 'green', 'blue']) as a parameter and returns the hexadecimal equivalent as a string. When used with the `df.apply()` method, it can create an entire new column of hex codes ready to be added to the dataframe as a new column.\n\n  ```\n  df['hex'] = df.apply(make_hex, axis=1)\n  ```\n\n  To learn more about the process of converting RGB to HEX, see the infographic below.\n\n  <img src=\"https://raw.githubusercontent.com/the-codingschool/TRAIN/main/color_classification/RGB to HEX.jpg\" width=600/>","metadata":{"id":"nj4g0aV34zdS"}},{"cell_type":"code","source":"def make_hex(row):\n  return '#%02X%02X%02X' % (row['red'], row['green'], row['blue'])\n\nfig = plt.figure(figsize=(14,8), layout='tight')\n\n# RGB-HEX Colors\nax = fig.add_subplot(121,projection='3d')\nax.scatter(rgb_df['red'], rgb_df['green'], rgb_df['blue'], c=rgb_df.apply(make_hex, axis=1), s=8, alpha=1.0)\nax.set_title('Actual Colors', fontweight='bold')\nax.set_xlabel('Red  ', fontweight='bold', color='red')\nax.set_ylabel('Green', fontweight='bold', color='green')\nax.set_zlabel('Blue ', fontweight='bold', color='blue')\nax.set_box_aspect(None, zoom=0.85)\n\n# Label Colors\nax = fig.add_subplot(122,projection='3d')\nax.scatter(rgb_df['red'], rgb_df['green'], rgb_df['blue'], c=rgb_df['label'], s=8)\n# COMPLETE THIS CODE - title, axis labels, aspect\n\nplt.show()","metadata":{"id":"E_btmXWPI75b","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #3: Decide independent and dependent variables**\n\nFor this problem, we are interested in how the `red`, `green`, and `blue` values affect what name is given to a color. Since the `label` of a color is a string, we also need to *encode* the color labels by assigning a number to each one.\n\n\n","metadata":{"id":"S0kwslkFJLvO"}},{"cell_type":"code","source":"encoded_labels = [colors.index(c) for c in rgb_df['label']]\nfeatures = # COMPLETE THIS CODE","metadata":{"id":"35Dqmq3wIyAf","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #4: Split data into training and testing data**\n","metadata":{"id":"EwOH_VssvQQI"}},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"8r9CoIZiItno","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #5: Hyperparameter Tuning**\n\nComplete and run the given code below to find the optimal k for our model. What is this k?","metadata":{"id":"T8B6OJ4SvcER"}},{"cell_type":"code","source":"scores = {}\nfor n in range(1,60,2):\n    full_model = KNeighborsClassifier(n_neighbors = n)\n    full_model.fit(X_train, y_train)\n    pred = full_model.predict(X_test)\n    scores[n] = sum(pred == y_test)/len(pred) * 100\n\n\nplt.title(\"Accuracy on Test set across Hyperparameter values\")\nplt.plot(scores.keys(), scores.values(), label = 'Scores for all K')\n\ntop_score = max(scores.values())\nbest_k = {v:k for k,v in scores.items()}[top_score]\nplt.scatter([best_k], [top_score], color = 'g', marker = '*', s = 200, label = 'Best Perfomance')\n\nplt.xlabel('K-Neighbors')\nplt.ylabel('Prediction Accuracy (%)')\nplt.legend()\nplt.show()\n\nprint(\"Top score of optimal classifier: \" + str(top_score))\nprint(\"Best Value of K: \" + str(best_k))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":508},"id":"1C04D-WzAwLY","outputId":"31dfbacb-87bb-419f-f14b-e4ed7e97c4bb","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #6: Initialize & Evaluate the model using the optimal k value**\n\n\nAfter fitting your model and making a prediction, print the accuracy and confusion matrix for your model's performance on the test set.","metadata":{"id":"rHWQG5xJv1rb"}},{"cell_type":"code","source":"# COMPLETE THIS CODE","metadata":{"id":"dOF8Axl9HP8K","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Step #7: Visualize your results**\n\nAnalyzing colors can be an intensely visual process, and evaluating model predictions may heavily rely on visual confirmation. Because of this, it is incredibly helpful to have stylized outputs that reflect the actual color of the sample and the color of the label it has been assigned. The way we perceive colors is often subjective, and the boundary that separates one color from its neighbor on the spectrum isn't rigidly defined.\n\nYour task is to compile the actual labels, predicted labels, and hex codes into a single dataframe as columns. Then we can use special output styling techniques to manually compare the actual and predicted labels.","metadata":{"id":"oczoaQlu8thP"}},{"cell_type":"code","source":"actual_labels = [colors[l] for l in y_test]   # return the encoded labels to the color names\npredicted_labels = [# COMPLETE THIS CODE\n\nresults_df = X_test.copy()\nresults_df['actual'] = # COMPLETE THIS CODE\nresults_df['predicted'] = # COMPLETE THIS CODE\nresults_df['hex'] = # COMPLETE THIS CODE\n\nresults_df.head()","metadata":{"id":"YICPIXGYHnSL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##### **Styled Table Output**\n\n- `output_styling()` - Takes a feature column as a parameter and returns a list of styling instructions for each column value as strings. These styling instructions are CSS ([cascading style sheets](https://www.w3schools.com/css/css_intro.asp)) ***attribute:value*** pairs. The primary attributes to consider are:\n    - **Background Color** `background-color` - Accepts hex codes (ex: #012D9C) and some standard [color names](https://developer.mozilla.org/en-US/docs/Web/CSS/named-color) (ex: 'red'). At a glance, the background should show us exactly what the sample color looks like *(hex code)*.\n    - **Text Color** `color` - Accepts hex codes (ex: #012D9C) and some standard [color names](https://developer.mozilla.org/en-US/docs/Web/CSS/named-color) (ex: 'red').\n    - **Text Alignment** `text-align` - Will align text to the left, right, or center of the cell.\n  \n  When the name of this function is used as a parameter in this method call `df.style.apply()` it is called on each feature column in `df`.","metadata":{"id":"Rzr0sM2L_Z07"}},{"cell_type":"code","source":"def output_styling(column):\n  if column.name == 'hex':\n    return ['text-align: center; background-color: ' + val for val in column]\n  if column.name not in ['red','green','blue']:\n    return ['text-align: center; font-weight: bold; color: ' + val for val in column]\n  return ['' for val in column]\n\nresults_df.style.apply(output_styling)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DSHlLpadwfQp","outputId":"f663cf56-7c1b-4a95-e053-ebe742620dfa","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n **[OPTIONAL]**\n\nMake additional 3D scatter plots of the RGB color data used to test the model. Consider comparing the actual/predicted labels and the actual RGB color.","metadata":{"id":"9QqMmCxKAyh_"}},{"cell_type":"code","source":"fig = plt.figure(figsize=(17,8), layout='tight')\n\n# Actual Label\nax = fig.add_subplot(131,projection='3d')\nax.scatter(# COMPLETE THIS CODE\nax.set_title('Actual Color Labels', fontweight='bold')\nax.set_xlabel('Red  ', fontweight='bold', color='red')\nax.set_ylabel(# COMPLETE THIS CODE\nax.set_zlabel(# COMPLETE THIS CODE\nax.set_box_aspect(None, zoom=0.85)\n\n# Predicted Label\nax = fig.add_subplot(132,projection='3d')\n# COMPLETE THIS CODE\n\n\n# RGB-HEX Colors\nax = fig.add_subplot(133,projection='3d')\n# COMPLETE THIS CODE\n\n\nplt.show()","metadata":{"id":"f5YhFwi_IAx0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n\n# End of Notebook\n\n© 2025 The Coding School, All rights reserved","metadata":{"id":"MRcj78PpQ2Xz"}}]}